2025-02-13 13:46:42.195 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-13 13:46:42.771 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-13 13:46:42.774 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained                ./params/swin_tiny_iterative_box_refinement_COCO.pth
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-13 13:46:43.256 | ERROR    | __main__:<module>:328 - An error has been caught in function '<module>', process 'MainProcess' (17252), thread 'MainThread' (17480):
Traceback (most recent call last):

> File "main.py", line 328, in <module>
    main(args)
    │    └ Namespace(aux_loss=True, backbone='swin_tiny', batch_size=2, bbox_loss_coef=2.5, clip_max_norm=0.1, coco_panoptic_path=None, ...
    └ <function main at 0x000001E49FD10B80>

  File "main.py", line 187, in main
    model, criterion, postprocessors = build_model(args)
                                       │           └ Namespace(aux_loss=True, backbone='swin_tiny', batch_size=2, bbox_loss_coef=2.5, clip_max_norm=0.1, coco_panoptic_path=None, ...
                                       └ <function build_model at 0x000001E4884BEEE0>

  File "D:\pro\ILCN\models\__init__.py", line 14, in build_model
    return build(args)
           │     └ Namespace(aux_loss=True, backbone='swin_tiny', batch_size=2, bbox_loss_coef=2.5, clip_max_norm=0.1, coco_panoptic_path=None, ...
           └ <function build at 0x000001E49FCA7B80>

  File "D:\pro\ILCN\models\hoi.py", line 522, in build
    backbone = build_backbone(args)
               │              └ Namespace(aux_loss=True, backbone='swin_tiny', batch_size=2, bbox_loss_coef=2.5, clip_max_norm=0.1, coco_panoptic_path=None, ...
               └ <function build_backbone at 0x000001E4884C7310>

  File "D:\pro\ILCN\models\backbone.py", line 162, in build_backbone
    backbone = Backbone(
               └ <class 'models.backbone.Backbone'>

  File "D:\pro\ILCN\models\backbone.py", line 135, in __init__
    super().__init__(backbone, backbone_name, num_feature_levels, pretrained)
                     │         │              │                   └ './params/swin_tiny_iterative_box_refinement_COCO.pth'
                     │         │              └ 4
                     │         └ 'swin_tiny'
                     └ SwinTransformer(
                         (patch_embed): PatchEmbed(
                           (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
                           (norm): LayerN...

  File "D:\pro\ILCN\models\backbone.py", line 80, in __init__
    backbone.init_weights(pretrained)
    │        │            └ './params/swin_tiny_iterative_box_refinement_COCO.pth'
    │        └ <function SwinTransformer.init_weights at 0x000001E4884E1CA0>
    └ SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerN...

  File "D:\pro\ILCN\models\swin_transformer.py", line 719, in init_weights
    load_checkpoint(self, pretrained, strict=False)
    │               │     └ './params/swin_tiny_iterative_box_refinement_COCO.pth'
    │               └ SwinTransformer(
    │                   (patch_embed): PatchEmbed(
    │                     (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
    │                     (norm): LayerN...
    └ <function load_checkpoint at 0x000001E4884E1280>

  File "D:\pro\ILCN\models\swin_transformer.py", line 144, in load_checkpoint
    table_current = model.state_dict()[table_key]
                    │     │            └ 'backbone.0.body.layers.0.blocks.0.attn.relative_position_bias_table'
                    │     └ <function Module.state_dict at 0x000001E481761550>
                    └ SwinTransformer(
                        (patch_embed): PatchEmbed(
                          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
                          (norm): LayerN...

KeyError: 'backbone.0.body.layers.0.blocks.0.attn.relative_position_bias_table'
2025-02-13 13:48:03.362 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-13 13:48:03.840 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-13 13:48:03.842 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-13 13:48:04.424 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-13 13:48:17.980 | ERROR    | __main__:<module>:328 - An error has been caught in function '<module>', process 'MainProcess' (17044), thread 'MainThread' (16596):
Traceback (most recent call last):

> File "main.py", line 328, in <module>
    main(args)
    │    └ Namespace(aux_loss=True, backbone='swin_tiny', batch_size=2, bbox_loss_coef=2.5, clip_max_norm=0.1, coco_panoptic_path=None, ...
    └ <function main at 0x000001C7FE4FB9D0>

  File "main.py", line 286, in main
    train_stats = train_one_epoch(
                  └ <function train_one_epoch at 0x000001C7E5D1B040>

  File "D:\pro\ILCN\engine.py", line 45, in train_one_epoch
    outputs = model(samples)
              │     └ tensor([[[[-0.9192, -0.9192, -0.9192,  ...,  0.0000,  0.0000,  0.0000],
              │                 [-0.9192, -0.9192, -0.9192,  ...,  0.0000, ...
              └ PA2LG(
                  (transformer): DeformableTransformer(
                    (encoder): DeformableTransformerEncoder(
                      (layers): ModuleList(
                     ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.9192, -0.9192, -0.9192,  ...,  0.0000,  0.0000,  0.0000],
           │    │                       [-0.9192, -0.9192, -0.9192,  ...,  0.0000,...
           │    └ <function Module._call_impl at 0x000001C7E00B0040>
           └ PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
                   (layers): ModuleList(
                  ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.9192, -0.9192, -0.9192,  ...,  0.0000,  0.0000,  0.0000],
           │                         [-0.9192, -0.9192, -0.9192,  ...,  0.0000,...
           └ <bound method PA2LG.forward of PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
               ...

  File "D:\pro\ILCN\models\hoi.py", line 187, in forward
    h_hs, o_hs, rel_hs, layout, init_reference, inter_references = self.transformer(srcs, masks, pos, query_embeds)
                                                                   │                │     │      │    └ Parameter containing:
                                                                   │                │     │      │      tensor([[-0.2682, -0.1382, -1.1603,  ..., -1.6692, -1.4299, -1.6421],
                                                                   │                │     │      │              [ 0.6555, -0.3442, -0.833...
                                                                   │                │     │      └ [tensor([[[[ 3.2719e-02,  3.2719e-02,  3.2719e-02,  ..., -9.6261e-02,
                                                                   │                │     │                   -9.6261e-02, -9.6261e-02],
                                                                   │                │     │                  [ 9.801...
                                                                   │                │     └ [tensor([[[False, False, False,  ...,  True,  True,  True],
                                                                   │                │                [False, False, False,  ...,  True,  True,  True],
                                                                   │                │             ...
                                                                   │                └ [tensor([[[[ 0.3051,  0.6926, -0.1737,  ..., -0.7589, -0.9284, -0.0293],
                                                                   │                            [ 0.4358,  0.2120, -0.1917,  ..., -0.7175,...
                                                                   └ PA2LG(
                                                                       (transformer): DeformableTransformer(
                                                                         (encoder): DeformableTransformerEncoder(
                                                                           (layers): ModuleList(
                                                                          ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ ([tensor([[[[ 0.3051,  0.6926, -0.1737,  ..., -0.7589, -0.9284, -0.0293],
           │    │                       [ 0.4358,  0.2120, -0.1917,  ..., -0.7175...
           │    └ <function Module._call_impl at 0x000001C7E00B0040>
           └ DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers): ModuleList(
                   (0-5): 6 x DeformableTransf...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ ([tensor([[[[ 0.3051,  0.6926, -0.1737,  ..., -0.7589, -0.9284, -0.0293],
           │                         [ 0.4358,  0.2120, -0.1917,  ..., -0.7175...
           └ <bound method DeformableTransformer.forward of DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers)...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 141, in forward
    h_hs, o_hs, rel_hs, layout, inter_references = self.decoder(tgt, reference_points, memory, spatial_shapes,
                                                   │            │    │                 │       └ tensor([[ 96, 128],
                                                   │            │    │                 │                 [ 48,  64],
                                                   │            │    │                 │                 [ 24,  32],
                                                   │            │    │                 │                 [ 12,  16]], device='cuda:0')
                                                   │            │    │                 └ tensor([[[-0.0519,  0.0657,  0.0984,  ..., -0.0666,  0.0346,  0.1634],
                                                   │            │    │                            [ 0.0203,  0.1605,  0.2340,  ..., -0.1197,  0...
                                                   │            │    └ tensor([[[0.4088, 0.4468],
                                                   │            │               [0.4957, 0.3412],
                                                   │            │               [0.9144, 0.4196],
                                                   │            │               [0.4548, 0.3619],
                                                   │            │               [0.9182,...
                                                   │            └ tensor([[[-1.2325, -0.6712, -1.1083,  ..., -1.6692, -1.4299, -1.6421],
                                                   │                       [-0.1627, -0.3660, -0.1090,  ...,  0.7059,  1...
                                                   └ DeformableTransformer(
                                                       (encoder): DeformableTransformerEncoder(
                                                         (layers): ModuleList(
                                                           (0-5): 6 x DeformableTransf...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-1.2325, -0.6712, -1.1083,  ..., -1.6692, -1.4299, -1.6421],
           │    │                      [-0.1627, -0.3660, -0.1090,  ...,  0.7059,  ...
           │    └ <function Module._call_impl at 0x000001C7E00B0040>
           └ DeformableTransformerDecoder(
               (layers): ModuleList(
                 (0-5): 6 x DeformableTransformerDecoderLayer(
                   (cross_attn): M...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-1.2325, -0.6712, -1.1083,  ..., -1.6692, -1.4299, -1.6421],
           │                        [-0.1627, -0.3660, -0.1090,  ...,  0.7059,  ...
           └ <bound method DeformableTransformerDecoder.forward of DeformableTransformerDecoder(
               (layers): ModuleList(
                 (0-5): 6 x De...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 355, in forward
    lay_inp = self.layout_ffn(lay_inp)
              │    │          └ tensor([[[ 2.5550e-02,  3.7236e-02,  1.6978e-02,  ...,  1.4021e-01,
              │    │                      -1.3816e+01, -2.0285e-02],
              │    │                     [ 3.0984e-0...
              │    └ <function DeformableTransformerDecoder.layout_ffn at 0x000001C7FE4D5550>
              └ DeformableTransformerDecoder(
                  (layers): ModuleList(
                    (0-5): 6 x DeformableTransformerDecoderLayer(
                      (cross_attn): M...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 292, in layout_ffn
    tgt = self.norm4(self.linear3(tgt))
          │          │            └ tensor([[[ 2.5550e-02,  3.7236e-02,  1.6978e-02,  ...,  1.4021e-01,
          │          │                        -1.3816e+01, -2.0285e-02],
          │          │                       [ 3.0984e-0...
          │          └ DeformableTransformerDecoder(
          │              (layers): ModuleList(
          │                (0-5): 6 x DeformableTransformerDecoderLayer(
          │                  (cross_attn): M...
          └ DeformableTransformerDecoder(
              (layers): ModuleList(
                (0-5): 6 x DeformableTransformerDecoderLayer(
                  (cross_attn): M...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1729, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")

AttributeError: 'DeformableTransformerDecoder' object has no attribute 'norm4'
2025-02-13 13:54:07.470 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-13 13:54:07.945 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-13 13:54:07.947 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-13 13:54:08.536 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-13 13:56:43.116 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-13 13:56:43.598 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-13 13:56:43.600 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-13 13:56:44.137 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-13 13:56:57.119 | INFO     | util.misc:log_every:287 - 
Epoch: [0]  [    0/18816]  eta: 2 days, 11:05:50  lr: 0.000100  obj_class_error: 100.00  loss: 104.0480 (104.0480)  loss_obj_ce: 1.0419 (1.0419)  loss_verb_ce: 8.9908 (8.9908)  loss_sub_bbox: 2.8908 (2.8908)  loss_obj_bbox: 2.7149 (2.7149)  loss_sub_giou: 1.0000 (1.0000)  loss_obj_giou: 1.0432 (1.0432)  loss_obj_ce_0: 0.9547 (0.9547)  loss_verb_ce_0: 8.9954 (8.9954)  loss_sub_bbox_0: 2.3231 (2.3231)  loss_obj_bbox_0: 2.0721 (2.0721)  loss_sub_giou_0: 0.9542 (0.9542)  loss_obj_giou_0: 0.9993 (0.9993)  loss_obj_ce_1: 1.0257 (1.0257)  loss_verb_ce_1: 8.8801 (8.8801)  loss_sub_bbox_1: 2.8292 (2.8292)  loss_obj_bbox_1: 2.5782 (2.5782)  loss_sub_giou_1: 0.9984 (0.9984)  loss_obj_giou_1: 1.0457 (1.0457)  loss_obj_ce_2: 0.9686 (0.9686)  loss_verb_ce_2: 8.8583 (8.8583)  loss_sub_bbox_2: 2.8751 (2.8751)  loss_obj_bbox_2: 2.7472 (2.7472)  loss_sub_giou_2: 1.0012 (1.0012)  loss_obj_giou_2: 1.0849 (1.0849)  loss_obj_ce_3: 0.9645 (0.9645)  loss_verb_ce_3: 8.8845 (8.8845)  loss_sub_bbox_3: 2.8858 (2.8858)  loss_obj_bbox_3: 2.7579 (2.7579)  loss_sub_giou_3: 1.0004 (1.0004)  loss_obj_giou_3: 1.0835 (1.0835)  loss_obj_ce_4: 0.9793 (0.9793)  loss_verb_ce_4: 8.8715 (8.8715)  loss_sub_bbox_4: 2.9164 (2.9164)  loss_obj_bbox_4: 2.7902 (2.7902)  loss_sub_giou_4: 1.0000 (1.0000)  loss_obj_giou_4: 1.0410 (1.0410)  loss_obj_ce_unscaled: 1.0419 (1.0419)  obj_class_error_unscaled: 100.0000 (100.0000)  loss_verb_ce_unscaled: 8.9908 (8.9908)  loss_sub_bbox_unscaled: 1.1563 (1.1563)  loss_obj_bbox_unscaled: 1.0860 (1.0860)  loss_sub_giou_unscaled: 1.0000 (1.0000)  loss_obj_giou_unscaled: 1.0432 (1.0432)  obj_cardinality_error_unscaled: 62.0000 (62.0000)  loss_obj_ce_0_unscaled: 0.9547 (0.9547)  loss_verb_ce_0_unscaled: 8.9954 (8.9954)  loss_sub_bbox_0_unscaled: 0.9292 (0.9292)  loss_obj_bbox_0_unscaled: 0.8288 (0.8288)  loss_sub_giou_0_unscaled: 0.9542 (0.9542)  loss_obj_giou_0_unscaled: 0.9993 (0.9993)  obj_cardinality_error_0_unscaled: 62.0000 (62.0000)  loss_obj_ce_1_unscaled: 1.0257 (1.0257)  loss_verb_ce_1_unscaled: 8.8801 (8.8801)  loss_sub_bbox_1_unscaled: 1.1317 (1.1317)  loss_obj_bbox_1_unscaled: 1.0313 (1.0313)  loss_sub_giou_1_unscaled: 0.9984 (0.9984)  loss_obj_giou_1_unscaled: 1.0457 (1.0457)  obj_cardinality_error_1_unscaled: 62.0000 (62.0000)  loss_obj_ce_2_unscaled: 0.9686 (0.9686)  loss_verb_ce_2_unscaled: 8.8583 (8.8583)  loss_sub_bbox_2_unscaled: 1.1501 (1.1501)  loss_obj_bbox_2_unscaled: 1.0989 (1.0989)  loss_sub_giou_2_unscaled: 1.0012 (1.0012)  loss_obj_giou_2_unscaled: 1.0849 (1.0849)  obj_cardinality_error_2_unscaled: 62.0000 (62.0000)  loss_obj_ce_3_unscaled: 0.9645 (0.9645)  loss_verb_ce_3_unscaled: 8.8845 (8.8845)  loss_sub_bbox_3_unscaled: 1.1543 (1.1543)  loss_obj_bbox_3_unscaled: 1.1032 (1.1032)  loss_sub_giou_3_unscaled: 1.0004 (1.0004)  loss_obj_giou_3_unscaled: 1.0835 (1.0835)  obj_cardinality_error_3_unscaled: 62.0000 (62.0000)  loss_obj_ce_4_unscaled: 0.9793 (0.9793)  loss_verb_ce_4_unscaled: 8.8715 (8.8715)  loss_sub_bbox_4_unscaled: 1.1666 (1.1666)  loss_obj_bbox_4_unscaled: 1.1161 (1.1161)  loss_sub_giou_4_unscaled: 1.0000 (1.0000)  loss_obj_giou_4_unscaled: 1.0410 (1.0410)  obj_cardinality_error_4_unscaled: 62.0000 (62.0000)  time: 11.3069  data: 6.2952  max mem: 5224
2025-02-13 14:03:51.889 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-13 14:03:52.409 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-13 14:03:52.412 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-13 14:03:52.879 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-13 14:04:03.933 | ERROR    | __main__:<module>:328 - An error has been caught in function '<module>', process 'MainProcess' (5020), thread 'MainThread' (6396):
Traceback (most recent call last):

> File "main.py", line 328, in <module>
    main(args)
    │    └ Namespace(aux_loss=True, backbone='swin_tiny', batch_size=2, bbox_loss_coef=2.5, clip_max_norm=0.1, coco_panoptic_path=None, ...
    └ <function main at 0x000002037F3CDCA0>

  File "main.py", line 286, in main
    train_stats = train_one_epoch(
                  └ <function train_one_epoch at 0x0000020369BBD040>

  File "D:\pro\ILCN\engine.py", line 45, in train_one_epoch
    outputs = model(samples)
              │     └ tensor([[[[-1.8953, -1.8953, -1.9124,  ...,  0.0000,  0.0000,  0.0000],
              │                 [-1.8953, -1.8953, -1.9124,  ...,  0.0000, ...
              └ PA2LG(
                  (transformer): DeformableTransformer(
                    (encoder): DeformableTransformerEncoder(
                      (layers): ModuleList(
                     ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-1.8953, -1.8953, -1.9124,  ...,  0.0000,  0.0000,  0.0000],
           │    │                       [-1.8953, -1.8953, -1.9124,  ...,  0.0000,...
           │    └ <function Module._call_impl at 0x0000020363F50040>
           └ PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
                   (layers): ModuleList(
                  ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-1.8953, -1.8953, -1.9124,  ...,  0.0000,  0.0000,  0.0000],
           │                         [-1.8953, -1.8953, -1.9124,  ...,  0.0000,...
           └ <bound method PA2LG.forward of PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
               ...

  File "D:\pro\ILCN\models\hoi.py", line 187, in forward
    h_hs, o_hs, rel_hs, layout, init_reference, inter_references = self.transformer(srcs, masks, pos, query_embeds)
                                                                   │                │     │      │    └ Parameter containing:
                                                                   │                │     │      │      tensor([[-0.1772, -1.0742, -0.3515,  ...,  0.8880, -1.0976, -0.2068],
                                                                   │                │     │      │              [-0.6940, -1.3653, -0.049...
                                                                   │                │     │      └ [tensor([[[[ 3.9260e-02,  3.9260e-02,  3.9260e-02,  ..., -9.6261e-02,
                                                                   │                │     │                   -9.6261e-02, -9.6261e-02],
                                                                   │                │     │                  [ 1.175...
                                                                   │                │     └ [tensor([[[False, False, False,  ...,  True,  True,  True],
                                                                   │                │                [False, False, False,  ...,  True,  True,  True],
                                                                   │                │             ...
                                                                   │                └ [tensor([[[[ 8.4783e-01, -2.7520e-01, -6.5010e-01,  ..., -7.4776e-01,
                                                                   │                             -4.4010e-01, -3.2981e-01],
                                                                   │                            [ 1.994...
                                                                   └ PA2LG(
                                                                       (transformer): DeformableTransformer(
                                                                         (encoder): DeformableTransformerEncoder(
                                                                           (layers): ModuleList(
                                                                          ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ ([tensor([[[[ 8.4783e-01, -2.7520e-01, -6.5010e-01,  ..., -7.4776e-01,
           │    │                        -4.4010e-01, -3.2981e-01],
           │    │                       [ 1.99...
           │    └ <function Module._call_impl at 0x0000020363F50040>
           └ DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers): ModuleList(
                   (0-5): 6 x DeformableTransf...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ ([tensor([[[[ 8.4783e-01, -2.7520e-01, -6.5010e-01,  ..., -7.4776e-01,
           │                          -4.4010e-01, -3.2981e-01],
           │                         [ 1.99...
           └ <bound method DeformableTransformer.forward of DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers)...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 137, in forward
    print(start.elapsed_time(end))
          │     │            └ <torch.cuda.Event 0x20368c00fb0>
          │     └ <function Event.elapsed_time at 0x0000020362BADE50>
          └ <torch.cuda.Event 0x20368bfc000>

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\cuda\streams.py", line 214, in elapsed_time
    return super().elapsed_time(end_event)
                                └ <torch.cuda.Event 0x20368c00fb0>

RuntimeError: CUDA error: device not ready
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-02-13 14:04:19.487 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-13 14:04:19.953 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-13 14:04:19.956 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-13 14:04:20.441 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-13 14:04:31.137 | ERROR    | __main__:<module>:328 - An error has been caught in function '<module>', process 'MainProcess' (5836), thread 'MainThread' (8028):
Traceback (most recent call last):

> File "main.py", line 328, in <module>
    main(args)
    │    └ Namespace(aux_loss=True, backbone='swin_tiny', batch_size=2, bbox_loss_coef=2.5, clip_max_norm=0.1, coco_panoptic_path=None, ...
    └ <function main at 0x00000285B7E0DCA0>

  File "main.py", line 286, in main
    train_stats = train_one_epoch(
                  └ <function train_one_epoch at 0x000002859F62B040>

  File "D:\pro\ILCN\engine.py", line 45, in train_one_epoch
    outputs = model(samples)
              │     └ tensor([[[[-1.8953, -1.8953, -1.9124,  ...,  0.0000,  0.0000,  0.0000],
              │                 [-1.8953, -1.8953, -1.9124,  ...,  0.0000, ...
              └ PA2LG(
                  (transformer): DeformableTransformer(
                    (encoder): DeformableTransformerEncoder(
                      (layers): ModuleList(
                     ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-1.8953, -1.8953, -1.9124,  ...,  0.0000,  0.0000,  0.0000],
           │    │                       [-1.8953, -1.8953, -1.9124,  ...,  0.0000,...
           │    └ <function Module._call_impl at 0x0000028599992040>
           └ PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
                   (layers): ModuleList(
                  ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-1.8953, -1.8953, -1.9124,  ...,  0.0000,  0.0000,  0.0000],
           │                         [-1.8953, -1.8953, -1.9124,  ...,  0.0000,...
           └ <bound method PA2LG.forward of PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
               ...

  File "D:\pro\ILCN\models\hoi.py", line 187, in forward
    h_hs, o_hs, rel_hs, layout, init_reference, inter_references = self.transformer(srcs, masks, pos, query_embeds)
                                                                   │                │     │      │    └ Parameter containing:
                                                                   │                │     │      │      tensor([[-0.1772, -1.0742, -0.3515,  ...,  0.8880, -1.0976, -0.2068],
                                                                   │                │     │      │              [-0.6940, -1.3653, -0.049...
                                                                   │                │     │      └ [tensor([[[[ 3.9260e-02,  3.9260e-02,  3.9260e-02,  ..., -9.6261e-02,
                                                                   │                │     │                   -9.6261e-02, -9.6261e-02],
                                                                   │                │     │                  [ 1.175...
                                                                   │                │     └ [tensor([[[False, False, False,  ...,  True,  True,  True],
                                                                   │                │                [False, False, False,  ...,  True,  True,  True],
                                                                   │                │             ...
                                                                   │                └ [tensor([[[[ 8.4783e-01, -2.7520e-01, -6.5010e-01,  ..., -7.4776e-01,
                                                                   │                             -4.4010e-01, -3.2981e-01],
                                                                   │                            [ 1.994...
                                                                   └ PA2LG(
                                                                       (transformer): DeformableTransformer(
                                                                         (encoder): DeformableTransformerEncoder(
                                                                           (layers): ModuleList(
                                                                          ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ ([tensor([[[[ 8.4783e-01, -2.7520e-01, -6.5010e-01,  ..., -7.4776e-01,
           │    │                        -4.4010e-01, -3.2981e-01],
           │    │                       [ 1.99...
           │    └ <function Module._call_impl at 0x0000028599992040>
           └ DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers): ModuleList(
                   (0-5): 6 x DeformableTransf...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ ([tensor([[[[ 8.4783e-01, -2.7520e-01, -6.5010e-01,  ..., -7.4776e-01,
           │                          -4.4010e-01, -3.2981e-01],
           │                         [ 1.99...
           └ <bound method DeformableTransformer.forward of DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers)...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 137, in forward
    print(start.elapsed_time(end))
          │     │            └ <torch.cuda.Event 0x2859e5bc3b0>
          │     └ <function Event.elapsed_time at 0x0000028593B72E50>
          └ <torch.cuda.Event 0x2859e5ba5f0>

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\cuda\streams.py", line 214, in elapsed_time
    return super().elapsed_time(end_event)
                                └ <torch.cuda.Event 0x2859e5bc3b0>

RuntimeError: CUDA error: device not ready
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-02-13 14:08:45.816 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-13 14:08:46.286 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-13 14:08:46.289 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-13 14:08:46.741 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-13 14:08:59.533 | INFO     | util.misc:log_every:287 - 
Epoch: [0]  [    0/18816]  eta: 2 days, 10:07:31  lr: 0.000100  obj_class_error: 100.00  loss: 104.0480 (104.0480)  loss_obj_ce: 1.0419 (1.0419)  loss_verb_ce: 8.9908 (8.9908)  loss_sub_bbox: 2.8908 (2.8908)  loss_obj_bbox: 2.7149 (2.7149)  loss_sub_giou: 1.0000 (1.0000)  loss_obj_giou: 1.0432 (1.0432)  loss_obj_ce_0: 0.9547 (0.9547)  loss_verb_ce_0: 8.9954 (8.9954)  loss_sub_bbox_0: 2.3231 (2.3231)  loss_obj_bbox_0: 2.0721 (2.0721)  loss_sub_giou_0: 0.9542 (0.9542)  loss_obj_giou_0: 0.9993 (0.9993)  loss_obj_ce_1: 1.0257 (1.0257)  loss_verb_ce_1: 8.8801 (8.8801)  loss_sub_bbox_1: 2.8292 (2.8292)  loss_obj_bbox_1: 2.5782 (2.5782)  loss_sub_giou_1: 0.9984 (0.9984)  loss_obj_giou_1: 1.0457 (1.0457)  loss_obj_ce_2: 0.9686 (0.9686)  loss_verb_ce_2: 8.8583 (8.8583)  loss_sub_bbox_2: 2.8751 (2.8751)  loss_obj_bbox_2: 2.7472 (2.7472)  loss_sub_giou_2: 1.0012 (1.0012)  loss_obj_giou_2: 1.0849 (1.0849)  loss_obj_ce_3: 0.9645 (0.9645)  loss_verb_ce_3: 8.8845 (8.8845)  loss_sub_bbox_3: 2.8858 (2.8858)  loss_obj_bbox_3: 2.7579 (2.7579)  loss_sub_giou_3: 1.0004 (1.0004)  loss_obj_giou_3: 1.0835 (1.0835)  loss_obj_ce_4: 0.9793 (0.9793)  loss_verb_ce_4: 8.8715 (8.8715)  loss_sub_bbox_4: 2.9164 (2.9164)  loss_obj_bbox_4: 2.7902 (2.7902)  loss_sub_giou_4: 1.0000 (1.0000)  loss_obj_giou_4: 1.0410 (1.0410)  loss_obj_ce_unscaled: 1.0419 (1.0419)  obj_class_error_unscaled: 100.0000 (100.0000)  loss_verb_ce_unscaled: 8.9908 (8.9908)  loss_sub_bbox_unscaled: 1.1563 (1.1563)  loss_obj_bbox_unscaled: 1.0860 (1.0860)  loss_sub_giou_unscaled: 1.0000 (1.0000)  loss_obj_giou_unscaled: 1.0432 (1.0432)  obj_cardinality_error_unscaled: 62.0000 (62.0000)  loss_obj_ce_0_unscaled: 0.9547 (0.9547)  loss_verb_ce_0_unscaled: 8.9954 (8.9954)  loss_sub_bbox_0_unscaled: 0.9292 (0.9292)  loss_obj_bbox_0_unscaled: 0.8288 (0.8288)  loss_sub_giou_0_unscaled: 0.9542 (0.9542)  loss_obj_giou_0_unscaled: 0.9993 (0.9993)  obj_cardinality_error_0_unscaled: 62.0000 (62.0000)  loss_obj_ce_1_unscaled: 1.0257 (1.0257)  loss_verb_ce_1_unscaled: 8.8801 (8.8801)  loss_sub_bbox_1_unscaled: 1.1317 (1.1317)  loss_obj_bbox_1_unscaled: 1.0313 (1.0313)  loss_sub_giou_1_unscaled: 0.9984 (0.9984)  loss_obj_giou_1_unscaled: 1.0457 (1.0457)  obj_cardinality_error_1_unscaled: 62.0000 (62.0000)  loss_obj_ce_2_unscaled: 0.9686 (0.9686)  loss_verb_ce_2_unscaled: 8.8583 (8.8583)  loss_sub_bbox_2_unscaled: 1.1501 (1.1501)  loss_obj_bbox_2_unscaled: 1.0989 (1.0989)  loss_sub_giou_2_unscaled: 1.0012 (1.0012)  loss_obj_giou_2_unscaled: 1.0849 (1.0849)  obj_cardinality_error_2_unscaled: 62.0000 (62.0000)  loss_obj_ce_3_unscaled: 0.9645 (0.9645)  loss_verb_ce_3_unscaled: 8.8845 (8.8845)  loss_sub_bbox_3_unscaled: 1.1543 (1.1543)  loss_obj_bbox_3_unscaled: 1.1032 (1.1032)  loss_sub_giou_3_unscaled: 1.0004 (1.0004)  loss_obj_giou_3_unscaled: 1.0835 (1.0835)  obj_cardinality_error_3_unscaled: 62.0000 (62.0000)  loss_obj_ce_4_unscaled: 0.9793 (0.9793)  loss_verb_ce_4_unscaled: 8.8715 (8.8715)  loss_sub_bbox_4_unscaled: 1.1666 (1.1666)  loss_obj_bbox_4_unscaled: 1.1161 (1.1161)  loss_sub_giou_4_unscaled: 1.0000 (1.0000)  loss_obj_giou_4_unscaled: 1.0410 (1.0410)  obj_cardinality_error_4_unscaled: 62.0000 (62.0000)  time: 11.1209  data: 6.1042  max mem: 5224
2025-02-13 14:09:22.882 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-13 14:09:23.363 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-13 14:09:23.365 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-13 14:09:23.843 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-13 14:09:36.610 | INFO     | util.misc:log_every:287 - 
Epoch: [0]  [    0/18816]  eta: 2 days, 10:02:25  lr: 0.000100  obj_class_error: 100.00  loss: 104.0480 (104.0480)  loss_obj_ce: 1.0419 (1.0419)  loss_verb_ce: 8.9908 (8.9908)  loss_sub_bbox: 2.8908 (2.8908)  loss_obj_bbox: 2.7149 (2.7149)  loss_sub_giou: 1.0000 (1.0000)  loss_obj_giou: 1.0432 (1.0432)  loss_obj_ce_0: 0.9547 (0.9547)  loss_verb_ce_0: 8.9954 (8.9954)  loss_sub_bbox_0: 2.3231 (2.3231)  loss_obj_bbox_0: 2.0721 (2.0721)  loss_sub_giou_0: 0.9542 (0.9542)  loss_obj_giou_0: 0.9993 (0.9993)  loss_obj_ce_1: 1.0257 (1.0257)  loss_verb_ce_1: 8.8801 (8.8801)  loss_sub_bbox_1: 2.8292 (2.8292)  loss_obj_bbox_1: 2.5782 (2.5782)  loss_sub_giou_1: 0.9984 (0.9984)  loss_obj_giou_1: 1.0457 (1.0457)  loss_obj_ce_2: 0.9686 (0.9686)  loss_verb_ce_2: 8.8583 (8.8583)  loss_sub_bbox_2: 2.8751 (2.8751)  loss_obj_bbox_2: 2.7472 (2.7472)  loss_sub_giou_2: 1.0012 (1.0012)  loss_obj_giou_2: 1.0849 (1.0849)  loss_obj_ce_3: 0.9645 (0.9645)  loss_verb_ce_3: 8.8845 (8.8845)  loss_sub_bbox_3: 2.8858 (2.8858)  loss_obj_bbox_3: 2.7579 (2.7579)  loss_sub_giou_3: 1.0004 (1.0004)  loss_obj_giou_3: 1.0835 (1.0835)  loss_obj_ce_4: 0.9793 (0.9793)  loss_verb_ce_4: 8.8715 (8.8715)  loss_sub_bbox_4: 2.9164 (2.9164)  loss_obj_bbox_4: 2.7902 (2.7902)  loss_sub_giou_4: 1.0000 (1.0000)  loss_obj_giou_4: 1.0410 (1.0410)  loss_obj_ce_unscaled: 1.0419 (1.0419)  obj_class_error_unscaled: 100.0000 (100.0000)  loss_verb_ce_unscaled: 8.9908 (8.9908)  loss_sub_bbox_unscaled: 1.1563 (1.1563)  loss_obj_bbox_unscaled: 1.0860 (1.0860)  loss_sub_giou_unscaled: 1.0000 (1.0000)  loss_obj_giou_unscaled: 1.0432 (1.0432)  obj_cardinality_error_unscaled: 62.0000 (62.0000)  loss_obj_ce_0_unscaled: 0.9547 (0.9547)  loss_verb_ce_0_unscaled: 8.9954 (8.9954)  loss_sub_bbox_0_unscaled: 0.9292 (0.9292)  loss_obj_bbox_0_unscaled: 0.8288 (0.8288)  loss_sub_giou_0_unscaled: 0.9542 (0.9542)  loss_obj_giou_0_unscaled: 0.9993 (0.9993)  obj_cardinality_error_0_unscaled: 62.0000 (62.0000)  loss_obj_ce_1_unscaled: 1.0257 (1.0257)  loss_verb_ce_1_unscaled: 8.8801 (8.8801)  loss_sub_bbox_1_unscaled: 1.1317 (1.1317)  loss_obj_bbox_1_unscaled: 1.0313 (1.0313)  loss_sub_giou_1_unscaled: 0.9984 (0.9984)  loss_obj_giou_1_unscaled: 1.0457 (1.0457)  obj_cardinality_error_1_unscaled: 62.0000 (62.0000)  loss_obj_ce_2_unscaled: 0.9686 (0.9686)  loss_verb_ce_2_unscaled: 8.8583 (8.8583)  loss_sub_bbox_2_unscaled: 1.1501 (1.1501)  loss_obj_bbox_2_unscaled: 1.0989 (1.0989)  loss_sub_giou_2_unscaled: 1.0012 (1.0012)  loss_obj_giou_2_unscaled: 1.0849 (1.0849)  obj_cardinality_error_2_unscaled: 62.0000 (62.0000)  loss_obj_ce_3_unscaled: 0.9645 (0.9645)  loss_verb_ce_3_unscaled: 8.8845 (8.8845)  loss_sub_bbox_3_unscaled: 1.1543 (1.1543)  loss_obj_bbox_3_unscaled: 1.1032 (1.1032)  loss_sub_giou_3_unscaled: 1.0004 (1.0004)  loss_obj_giou_3_unscaled: 1.0835 (1.0835)  obj_cardinality_error_3_unscaled: 62.0000 (62.0000)  loss_obj_ce_4_unscaled: 0.9793 (0.9793)  loss_verb_ce_4_unscaled: 8.8715 (8.8715)  loss_sub_bbox_4_unscaled: 1.1666 (1.1666)  loss_obj_bbox_4_unscaled: 1.1161 (1.1161)  loss_sub_giou_4_unscaled: 1.0000 (1.0000)  loss_obj_giou_4_unscaled: 1.0410 (1.0410)  obj_cardinality_error_4_unscaled: 62.0000 (62.0000)  time: 11.1047  data: 6.0768  max mem: 5224
2025-02-13 14:12:09.580 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-13 14:12:10.092 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-13 14:12:10.094 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-13 14:12:10.580 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-13 14:12:23.471 | INFO     | util.misc:log_every:287 - 
Epoch: [0]  [    0/18816]  eta: 2 days, 10:11:05  lr: 0.000100  obj_class_error: 100.00  loss: 104.0480 (104.0480)  loss_obj_ce: 1.0419 (1.0419)  loss_verb_ce: 8.9908 (8.9908)  loss_sub_bbox: 2.8908 (2.8908)  loss_obj_bbox: 2.7149 (2.7149)  loss_sub_giou: 1.0000 (1.0000)  loss_obj_giou: 1.0432 (1.0432)  loss_obj_ce_0: 0.9547 (0.9547)  loss_verb_ce_0: 8.9954 (8.9954)  loss_sub_bbox_0: 2.3231 (2.3231)  loss_obj_bbox_0: 2.0721 (2.0721)  loss_sub_giou_0: 0.9542 (0.9542)  loss_obj_giou_0: 0.9993 (0.9993)  loss_obj_ce_1: 1.0257 (1.0257)  loss_verb_ce_1: 8.8801 (8.8801)  loss_sub_bbox_1: 2.8292 (2.8292)  loss_obj_bbox_1: 2.5782 (2.5782)  loss_sub_giou_1: 0.9984 (0.9984)  loss_obj_giou_1: 1.0457 (1.0457)  loss_obj_ce_2: 0.9686 (0.9686)  loss_verb_ce_2: 8.8583 (8.8583)  loss_sub_bbox_2: 2.8751 (2.8751)  loss_obj_bbox_2: 2.7472 (2.7472)  loss_sub_giou_2: 1.0012 (1.0012)  loss_obj_giou_2: 1.0849 (1.0849)  loss_obj_ce_3: 0.9645 (0.9645)  loss_verb_ce_3: 8.8845 (8.8845)  loss_sub_bbox_3: 2.8858 (2.8858)  loss_obj_bbox_3: 2.7579 (2.7579)  loss_sub_giou_3: 1.0004 (1.0004)  loss_obj_giou_3: 1.0835 (1.0835)  loss_obj_ce_4: 0.9793 (0.9793)  loss_verb_ce_4: 8.8715 (8.8715)  loss_sub_bbox_4: 2.9164 (2.9164)  loss_obj_bbox_4: 2.7902 (2.7902)  loss_sub_giou_4: 1.0000 (1.0000)  loss_obj_giou_4: 1.0410 (1.0410)  loss_obj_ce_unscaled: 1.0419 (1.0419)  obj_class_error_unscaled: 100.0000 (100.0000)  loss_verb_ce_unscaled: 8.9908 (8.9908)  loss_sub_bbox_unscaled: 1.1563 (1.1563)  loss_obj_bbox_unscaled: 1.0860 (1.0860)  loss_sub_giou_unscaled: 1.0000 (1.0000)  loss_obj_giou_unscaled: 1.0432 (1.0432)  obj_cardinality_error_unscaled: 62.0000 (62.0000)  loss_obj_ce_0_unscaled: 0.9547 (0.9547)  loss_verb_ce_0_unscaled: 8.9954 (8.9954)  loss_sub_bbox_0_unscaled: 0.9292 (0.9292)  loss_obj_bbox_0_unscaled: 0.8288 (0.8288)  loss_sub_giou_0_unscaled: 0.9542 (0.9542)  loss_obj_giou_0_unscaled: 0.9993 (0.9993)  obj_cardinality_error_0_unscaled: 62.0000 (62.0000)  loss_obj_ce_1_unscaled: 1.0257 (1.0257)  loss_verb_ce_1_unscaled: 8.8801 (8.8801)  loss_sub_bbox_1_unscaled: 1.1317 (1.1317)  loss_obj_bbox_1_unscaled: 1.0313 (1.0313)  loss_sub_giou_1_unscaled: 0.9984 (0.9984)  loss_obj_giou_1_unscaled: 1.0457 (1.0457)  obj_cardinality_error_1_unscaled: 62.0000 (62.0000)  loss_obj_ce_2_unscaled: 0.9686 (0.9686)  loss_verb_ce_2_unscaled: 8.8583 (8.8583)  loss_sub_bbox_2_unscaled: 1.1501 (1.1501)  loss_obj_bbox_2_unscaled: 1.0989 (1.0989)  loss_sub_giou_2_unscaled: 1.0012 (1.0012)  loss_obj_giou_2_unscaled: 1.0849 (1.0849)  obj_cardinality_error_2_unscaled: 62.0000 (62.0000)  loss_obj_ce_3_unscaled: 0.9645 (0.9645)  loss_verb_ce_3_unscaled: 8.8845 (8.8845)  loss_sub_bbox_3_unscaled: 1.1543 (1.1543)  loss_obj_bbox_3_unscaled: 1.1032 (1.1032)  loss_sub_giou_3_unscaled: 1.0004 (1.0004)  loss_obj_giou_3_unscaled: 1.0835 (1.0835)  obj_cardinality_error_3_unscaled: 62.0000 (62.0000)  loss_obj_ce_4_unscaled: 0.9793 (0.9793)  loss_verb_ce_4_unscaled: 8.8715 (8.8715)  loss_sub_bbox_4_unscaled: 1.1666 (1.1666)  loss_obj_bbox_4_unscaled: 1.1161 (1.1161)  loss_sub_giou_4_unscaled: 1.0000 (1.0000)  loss_obj_giou_4_unscaled: 1.0410 (1.0410)  obj_cardinality_error_4_unscaled: 62.0000 (62.0000)  time: 11.1323  data: 6.3067  max mem: 5224
2025-02-13 14:18:14.792 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-13 14:18:15.255 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-13 14:18:15.257 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-13 14:18:15.730 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-13 14:18:28.731 | INFO     | util.misc:log_every:287 - 
Epoch: [0]  [    0/18816]  eta: 2 days, 11:27:14  lr: 0.000100  obj_class_error: 100.00  loss: 75.9464 (75.9464)  loss_obj_ce: 1.0419 (1.0419)  loss_verb_ce: 4.3053 (4.3053)  loss_sub_bbox: 2.8908 (2.8908)  loss_obj_bbox: 2.7149 (2.7149)  loss_sub_giou: 1.0000 (1.0000)  loss_obj_giou: 1.0432 (1.0432)  loss_obj_ce_0: 0.9547 (0.9547)  loss_verb_ce_0: 4.3130 (4.3130)  loss_sub_bbox_0: 2.3231 (2.3231)  loss_obj_bbox_0: 2.0721 (2.0721)  loss_sub_giou_0: 0.9542 (0.9542)  loss_obj_giou_0: 0.9993 (0.9993)  loss_obj_ce_1: 1.0257 (1.0257)  loss_verb_ce_1: 4.1973 (4.1973)  loss_sub_bbox_1: 2.8292 (2.8292)  loss_obj_bbox_1: 2.5782 (2.5782)  loss_sub_giou_1: 0.9984 (0.9984)  loss_obj_giou_1: 1.0457 (1.0457)  loss_obj_ce_2: 0.9686 (0.9686)  loss_verb_ce_2: 4.1762 (4.1762)  loss_sub_bbox_2: 2.8751 (2.8751)  loss_obj_bbox_2: 2.7472 (2.7472)  loss_sub_giou_2: 1.0012 (1.0012)  loss_obj_giou_2: 1.0849 (1.0849)  loss_obj_ce_3: 0.9645 (0.9645)  loss_verb_ce_3: 4.2009 (4.2009)  loss_sub_bbox_3: 2.8858 (2.8858)  loss_obj_bbox_3: 2.7579 (2.7579)  loss_sub_giou_3: 1.0004 (1.0004)  loss_obj_giou_3: 1.0835 (1.0835)  loss_obj_ce_4: 0.9793 (0.9793)  loss_verb_ce_4: 4.1862 (4.1862)  loss_sub_bbox_4: 2.9164 (2.9164)  loss_obj_bbox_4: 2.7902 (2.7902)  loss_sub_giou_4: 1.0000 (1.0000)  loss_obj_giou_4: 1.0410 (1.0410)  loss_obj_ce_unscaled: 1.0419 (1.0419)  obj_class_error_unscaled: 100.0000 (100.0000)  loss_verb_ce_unscaled: 4.3053 (4.3053)  loss_sub_bbox_unscaled: 1.1563 (1.1563)  loss_obj_bbox_unscaled: 1.0860 (1.0860)  loss_sub_giou_unscaled: 1.0000 (1.0000)  loss_obj_giou_unscaled: 1.0432 (1.0432)  obj_cardinality_error_unscaled: 62.0000 (62.0000)  loss_obj_ce_0_unscaled: 0.9547 (0.9547)  loss_verb_ce_0_unscaled: 4.3130 (4.3130)  loss_sub_bbox_0_unscaled: 0.9292 (0.9292)  loss_obj_bbox_0_unscaled: 0.8288 (0.8288)  loss_sub_giou_0_unscaled: 0.9542 (0.9542)  loss_obj_giou_0_unscaled: 0.9993 (0.9993)  obj_cardinality_error_0_unscaled: 62.0000 (62.0000)  loss_obj_ce_1_unscaled: 1.0257 (1.0257)  loss_verb_ce_1_unscaled: 4.1973 (4.1973)  loss_sub_bbox_1_unscaled: 1.1317 (1.1317)  loss_obj_bbox_1_unscaled: 1.0313 (1.0313)  loss_sub_giou_1_unscaled: 0.9984 (0.9984)  loss_obj_giou_1_unscaled: 1.0457 (1.0457)  obj_cardinality_error_1_unscaled: 62.0000 (62.0000)  loss_obj_ce_2_unscaled: 0.9686 (0.9686)  loss_verb_ce_2_unscaled: 4.1762 (4.1762)  loss_sub_bbox_2_unscaled: 1.1501 (1.1501)  loss_obj_bbox_2_unscaled: 1.0989 (1.0989)  loss_sub_giou_2_unscaled: 1.0012 (1.0012)  loss_obj_giou_2_unscaled: 1.0849 (1.0849)  obj_cardinality_error_2_unscaled: 62.0000 (62.0000)  loss_obj_ce_3_unscaled: 0.9645 (0.9645)  loss_verb_ce_3_unscaled: 4.2009 (4.2009)  loss_sub_bbox_3_unscaled: 1.1543 (1.1543)  loss_obj_bbox_3_unscaled: 1.1032 (1.1032)  loss_sub_giou_3_unscaled: 1.0004 (1.0004)  loss_obj_giou_3_unscaled: 1.0835 (1.0835)  obj_cardinality_error_3_unscaled: 62.0000 (62.0000)  loss_obj_ce_4_unscaled: 0.9793 (0.9793)  loss_verb_ce_4_unscaled: 4.1862 (4.1862)  loss_sub_bbox_4_unscaled: 1.1666 (1.1666)  loss_obj_bbox_4_unscaled: 1.1161 (1.1161)  loss_sub_giou_4_unscaled: 1.0000 (1.0000)  loss_obj_giou_4_unscaled: 1.0410 (1.0410)  obj_cardinality_error_4_unscaled: 62.0000 (62.0000)  time: 11.3751  data: 6.4787  max mem: 5223
2025-02-17 14:03:48.240 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-17 14:03:48.949 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-17 14:03:48.952 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-17 14:03:49.790 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-17 14:04:07.209 | ERROR    | __main__:<module>:328 - An error has been caught in function '<module>', process 'MainProcess' (11140), thread 'MainThread' (18672):
Traceback (most recent call last):

> File "main.py", line 328, in <module>
    main(args)
    │    └ Namespace(aux_loss=True, backbone='swin_tiny', batch_size=2, bbox_loss_coef=2.5, clip_max_norm=0.1, coco_panoptic_path=None, ...
    └ <function main at 0x0000029E2158E940>

  File "main.py", line 286, in main
    train_stats = train_one_epoch(
                  └ <function train_one_epoch at 0x0000029E08D9D040>

  File "D:\pro\ILCN\engine.py", line 45, in train_one_epoch
    outputs = model(samples)
              │     └ tensor([[[[-0.0287,  0.0056,  0.0398,  ...,  0.0000,  0.0000,  0.0000],
              │                 [-0.0116,  0.0056,  0.0227,  ...,  0.0000, ...
              └ PA2LG(
                  (transformer): DeformableTransformer(
                    (encoder): DeformableTransformerEncoder(
                      (layers): ModuleList(
                     ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.0287,  0.0056,  0.0398,  ...,  0.0000,  0.0000,  0.0000],
           │    │                       [-0.0116,  0.0056,  0.0227,  ...,  0.0000,...
           │    └ <function Module._call_impl at 0x0000029E7FF51040>
           └ PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
                   (layers): ModuleList(
                  ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.0287,  0.0056,  0.0398,  ...,  0.0000,  0.0000,  0.0000],
           │                         [-0.0116,  0.0056,  0.0227,  ...,  0.0000,...
           └ <bound method PA2LG.forward of PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
               ...

  File "D:\pro\ILCN\models\hoi.py", line 188, in forward
    h_hs, o_hs, rel_hs, layout, init_reference, inter_references = self.transformer(srcs, masks, pos, query_embeds)
                                                                   │                │     │      │    └ Parameter containing:
                                                                   │                │     │      │      tensor([[-0.4572,  0.9193, -0.3002,  ..., -0.2561, -0.3352,  1.2931],
                                                                   │                │     │      │              [-0.6468,  1.8858,  0.732...
                                                                   │                │     │      └ [tensor([[[[ 4.3022e-02,  4.3022e-02,  4.3022e-02,  ..., -9.6261e-02,
                                                                   │                │     │                   -9.6261e-02, -9.6261e-02],
                                                                   │                │     │                  [ 1.287...
                                                                   │                │     └ [tensor([[[False, False, False,  ...,  True,  True,  True],
                                                                   │                │                [False, False, False,  ...,  True,  True,  True],
                                                                   │                │             ...
                                                                   │                └ [tensor([[[[ 5.6716e-01,  7.0616e-01,  1.5850e+00,  ..., -7.9683e-01,
                                                                   │                             -4.1618e-01, -3.6783e-01],
                                                                   │                            [ 7.738...
                                                                   └ PA2LG(
                                                                       (transformer): DeformableTransformer(
                                                                         (encoder): DeformableTransformerEncoder(
                                                                           (layers): ModuleList(
                                                                          ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ ([tensor([[[[ 5.6716e-01,  7.0616e-01,  1.5850e+00,  ..., -7.9683e-01,
           │    │                        -4.1618e-01, -3.6783e-01],
           │    │                       [ 7.73...
           │    └ <function Module._call_impl at 0x0000029E7FF51040>
           └ DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers): ModuleList(
                   (0-5): 6 x DeformableTransf...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ ([tensor([[[[ 5.6716e-01,  7.0616e-01,  1.5850e+00,  ..., -7.9683e-01,
           │                          -4.1618e-01, -3.6783e-01],
           │                         [ 7.73...
           └ <bound method DeformableTransformer.forward of DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers)...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 139, in forward
    h_hs, o_hs, rel_hs, inter_references = self.decoder(tgt, reference_points, memory, spatial_shapes,
                                           │            │    │                 │       └ tensor([[90, 80],
                                           │            │    │                 │                 [45, 40],
                                           │            │    │                 │                 [23, 20],
                                           │            │    │                 │                 [12, 10]], device='cuda:0')
                                           │            │    │                 └ tensor([[[-0.0771, -0.0732, -0.1309,  ..., -0.0225,  0.1080, -0.0214],
                                           │            │    │                            [ 0.0180,  0.0418,  0.2843,  ..., -0.0941,  0...
                                           │            │    └ tensor([[[0.7783, 0.9159],
                                           │            │               [0.7920, 0.2213],
                                           │            │               [0.0842, 0.7202],
                                           │            │               [0.3789, 0.8281],
                                           │            │               [0.9155,...
                                           │            └ tensor([[[-1.2241, -0.5669, -0.5742,  ..., -0.2561, -0.3352,  1.2931],
                                           │                       [ 0.0412,  1.1031, -0.4105,  ...,  0.2912,  1...
                                           └ DeformableTransformer(
                                               (encoder): DeformableTransformerEncoder(
                                                 (layers): ModuleList(
                                                   (0-5): 6 x DeformableTransf...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-1.2241, -0.5669, -0.5742,  ..., -0.2561, -0.3352,  1.2931],
           │    │                      [ 0.0412,  1.1031, -0.4105,  ...,  0.2912,  ...
           │    └ <function Module._call_impl at 0x0000029E7FF51040>
           └ DeformableTransformerDecoder(
               (layers): ModuleList(
                 (0-5): 6 x DeformableTransformerDecoderLayer(
                   (cross_attn): M...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-1.2241, -0.5669, -0.5742,  ..., -0.2561, -0.3352,  1.2931],
           │                        [ 0.0412,  1.1031, -0.4105,  ...,  0.2912,  ...
           └ <bound method DeformableTransformerDecoder.forward of DeformableTransformerDecoder(
               (layers): ModuleList(
                 (0-5): 6 x De...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 432, in forward
    rel_out, lay_out = self.rel_layers[lid](
                       │               └ 0
                       └ DeformableTransformerDecoder(
                           (layers): ModuleList(
                             (0-5): 6 x DeformableTransformerDecoderLayer(
                               (cross_attn): M...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-0.0348, -1.7222, -0.3447,  ..., -0.1195,  0.1414,  1.3274],
           │    │                      [ 1.9348, -0.0402,  0.3258,  ..., -1.4109,  ...
           │    └ <function Module._call_impl at 0x0000029E7FF51040>
           └ RelDeformableTransformerDecoderLayer(
               (cross_attn): MSDeformAttn(
                 (sampling_offsets): Linear(in_features=256, out_featu...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-0.0348, -1.7222, -0.3447,  ..., -0.1195,  0.1414,  1.3274],
           │                        [ 1.9348, -0.0402,  0.3258,  ..., -1.4109,  ...
           └ <bound method RelDeformableTransformerDecoderLayer.forward of RelDeformableTransformerDecoderLayer(
               (cross_attn): MSDeformA...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 341, in forward
    tgt2 = self.self_attn(q.transpose(0, 1), k.transpose(0, 1), tgt.transpose(0, 1))[0].transpose(0, 1)
           │              │ │                │ │                │   └ <method 'transpose' of 'torch._C.TensorBase' objects>
           │              │ │                │ │                └ tensor([[[-0.0348, -1.7222, -0.3447,  ..., -0.1195,  0.1414,  1.3274],
           │              │ │                │ │                           [ 1.9348, -0.0402,  0.3258,  ..., -1.4109,  0...
           │              │ │                │ └ <method 'transpose' of 'torch._C.TensorBase' objects>
           │              │ │                └ tensor([[[-0.3244, -1.6543, -0.1729,  ..., -0.4487,  0.6559,  1.8919],
           │              │ │                           [ 1.4090,  0.9768,  0.9939,  ..., -0.8509,  1...
           │              │ └ <method 'transpose' of 'torch._C.TensorBase' objects>
           │              └ tensor([[[-0.3244, -1.6543, -0.1729,  ..., -0.4487,  0.6559,  1.8919],
           │                         [ 1.4090,  0.9768,  0.9939,  ..., -0.8509,  1...
           └ RelDeformableTransformerDecoderLayer(
               (cross_attn): MSDeformAttn(
                 (sampling_offsets): Linear(in_features=256, out_featu...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-0.3244, -1.6543, -0.1729,  ..., -0.4487,  0.6559,  1.8919],
           │    │                      [-0.0768, -1.8913,  0.6300,  ..., -1.0504,  ...
           │    └ <function Module._call_impl at 0x0000029E7FF51040>
           └ MultiheadAttention(
               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
             )

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-0.3244, -1.6543, -0.1729,  ..., -0.4487,  0.6559,  1.8919],
           │                        [-0.0768, -1.8913,  0.6300,  ..., -1.0504,  ...
           └ <bound method MultiheadAttention.forward of MultiheadAttention(
               (out_proj): NonDynamicallyQuantizableLinear(in_features=512...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\activation.py", line 1275, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       │ └ <function multi_head_attention_forward at 0x0000029E030B5F70>
                                       └ <module 'torch.nn.functional' from 'C:\\Users\\ASUS\\.conda\\envs\\ilcn\\lib\\site-packages\\torch\\nn\\functional.py'>

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\functional.py", line 5400, in multi_head_attention_forward
    assert embed_dim == embed_dim_to_check, \
           │            └ 512
           └ 256

AssertionError: was expecting embedding dimension of 512, but got 256
2025-02-17 14:05:42.616 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-17 14:05:43.078 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-17 14:05:43.080 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-17 14:05:43.666 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-17 14:05:54.386 | ERROR    | __main__:<module>:328 - An error has been caught in function '<module>', process 'MainProcess' (10924), thread 'MainThread' (15484):
Traceback (most recent call last):

> File "main.py", line 328, in <module>
    main(args)
    │    └ Namespace(aux_loss=True, backbone='swin_tiny', batch_size=2, bbox_loss_coef=2.5, clip_max_norm=0.1, coco_panoptic_path=None, ...
    └ <function main at 0x000001A0A67CE940>

  File "main.py", line 286, in main
    train_stats = train_one_epoch(
                  └ <function train_one_epoch at 0x000001A08DFEB040>

  File "D:\pro\ILCN\engine.py", line 45, in train_one_epoch
    outputs = model(samples)
              │     └ tensor([[[[-0.0287,  0.0056,  0.0398,  ...,  0.0000,  0.0000,  0.0000],
              │                 [-0.0116,  0.0056,  0.0227,  ...,  0.0000, ...
              └ PA2LG(
                  (transformer): DeformableTransformer(
                    (encoder): DeformableTransformerEncoder(
                      (layers): ModuleList(
                     ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.0287,  0.0056,  0.0398,  ...,  0.0000,  0.0000,  0.0000],
           │    │                       [-0.0116,  0.0056,  0.0227,  ...,  0.0000,...
           │    └ <function Module._call_impl at 0x000001A088341040>
           └ PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
                   (layers): ModuleList(
                  ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.0287,  0.0056,  0.0398,  ...,  0.0000,  0.0000,  0.0000],
           │                         [-0.0116,  0.0056,  0.0227,  ...,  0.0000,...
           └ <bound method PA2LG.forward of PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
               ...

  File "D:\pro\ILCN\models\hoi.py", line 188, in forward
    h_hs, o_hs, rel_hs, layout, init_reference, inter_references = self.transformer(srcs, masks, pos, query_embeds)
                                                                   │                │     │      │    └ Parameter containing:
                                                                   │                │     │      │      tensor([[-0.4572,  0.9193, -0.3002,  ..., -0.2561, -0.3352,  1.2931],
                                                                   │                │     │      │              [-0.6468,  1.8858,  0.732...
                                                                   │                │     │      └ [tensor([[[[ 4.3022e-02,  4.3022e-02,  4.3022e-02,  ..., -9.6261e-02,
                                                                   │                │     │                   -9.6261e-02, -9.6261e-02],
                                                                   │                │     │                  [ 1.287...
                                                                   │                │     └ [tensor([[[False, False, False,  ...,  True,  True,  True],
                                                                   │                │                [False, False, False,  ...,  True,  True,  True],
                                                                   │                │             ...
                                                                   │                └ [tensor([[[[ 5.6716e-01,  7.0616e-01,  1.5850e+00,  ..., -7.9683e-01,
                                                                   │                             -4.1618e-01, -3.6783e-01],
                                                                   │                            [ 7.738...
                                                                   └ PA2LG(
                                                                       (transformer): DeformableTransformer(
                                                                         (encoder): DeformableTransformerEncoder(
                                                                           (layers): ModuleList(
                                                                          ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ ([tensor([[[[ 5.6716e-01,  7.0616e-01,  1.5850e+00,  ..., -7.9683e-01,
           │    │                        -4.1618e-01, -3.6783e-01],
           │    │                       [ 7.73...
           │    └ <function Module._call_impl at 0x000001A088341040>
           └ DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers): ModuleList(
                   (0-5): 6 x DeformableTransf...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ ([tensor([[[[ 5.6716e-01,  7.0616e-01,  1.5850e+00,  ..., -7.9683e-01,
           │                          -4.1618e-01, -3.6783e-01],
           │                         [ 7.73...
           └ <bound method DeformableTransformer.forward of DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers)...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 139, in forward
    h_hs, o_hs, rel_hs, inter_references = self.decoder(tgt, reference_points, memory, spatial_shapes,
                                           │            │    │                 │       └ tensor([[90, 80],
                                           │            │    │                 │                 [45, 40],
                                           │            │    │                 │                 [23, 20],
                                           │            │    │                 │                 [12, 10]], device='cuda:0')
                                           │            │    │                 └ tensor([[[-0.0771, -0.0732, -0.1309,  ..., -0.0225,  0.1080, -0.0214],
                                           │            │    │                            [ 0.0180,  0.0418,  0.2843,  ..., -0.0941,  0...
                                           │            │    └ tensor([[[0.7783, 0.9159],
                                           │            │               [0.7920, 0.2213],
                                           │            │               [0.0842, 0.7202],
                                           │            │               [0.3789, 0.8281],
                                           │            │               [0.9155,...
                                           │            └ tensor([[[-1.2241, -0.5669, -0.5742,  ..., -0.2561, -0.3352,  1.2931],
                                           │                       [ 0.0412,  1.1031, -0.4105,  ...,  0.2912,  1...
                                           └ DeformableTransformer(
                                               (encoder): DeformableTransformerEncoder(
                                                 (layers): ModuleList(
                                                   (0-5): 6 x DeformableTransf...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-1.2241, -0.5669, -0.5742,  ..., -0.2561, -0.3352,  1.2931],
           │    │                      [ 0.0412,  1.1031, -0.4105,  ...,  0.2912,  ...
           │    └ <function Module._call_impl at 0x000001A088341040>
           └ DeformableTransformerDecoder(
               (layers): ModuleList(
                 (0-5): 6 x DeformableTransformerDecoderLayer(
                   (cross_attn): M...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-1.2241, -0.5669, -0.5742,  ..., -0.2561, -0.3352,  1.2931],
           │                        [ 0.0412,  1.1031, -0.4105,  ...,  0.2912,  ...
           └ <bound method DeformableTransformerDecoder.forward of DeformableTransformerDecoder(
               (layers): ModuleList(
                 (0-5): 6 x De...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 432, in forward
    rel_out, lay_out = self.rel_layers[lid](
                       │               └ 0
                       └ DeformableTransformerDecoder(
                           (layers): ModuleList(
                             (0-5): 6 x DeformableTransformerDecoderLayer(
                               (cross_attn): M...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-0.0348, -1.7222, -0.3447,  ..., -0.1195,  0.1414,  1.3274],
           │    │                      [ 1.9348, -0.0402,  0.3258,  ..., -1.4109,  ...
           │    └ <function Module._call_impl at 0x000001A088341040>
           └ RelDeformableTransformerDecoderLayer(
               (cross_attn): MSDeformAttn(
                 (sampling_offsets): Linear(in_features=256, out_featu...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-0.0348, -1.7222, -0.3447,  ..., -0.1195,  0.1414,  1.3274],
           │                        [ 1.9348, -0.0402,  0.3258,  ..., -1.4109,  ...
           └ <bound method RelDeformableTransformerDecoderLayer.forward of RelDeformableTransformerDecoderLayer(
               (cross_attn): MSDeformA...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 341, in forward
    tgt2 = self.self_attn(q.transpose(0, 1), k.transpose(0, 1), tgt.transpose(0, 1))[0].transpose(0, 1)
           │              │ │                │ │                │   └ <method 'transpose' of 'torch._C.TensorBase' objects>
           │              │ │                │ │                └ tensor([[[-0.0348, -1.7222, -0.3447,  ..., -0.1195,  0.1414,  1.3274],
           │              │ │                │ │                           [ 1.9348, -0.0402,  0.3258,  ..., -1.4109,  0...
           │              │ │                │ └ <method 'transpose' of 'torch._C.TensorBase' objects>
           │              │ │                └ tensor([[[-0.5163, -1.4466, -0.1320,  ..., -0.4566,  0.5969,  1.3384],
           │              │ │                           [ 1.5631,  0.2174,  0.6958,  ..., -1.4672,  0...
           │              │ └ <method 'transpose' of 'torch._C.TensorBase' objects>
           │              └ tensor([[[-0.5163, -1.4466, -0.1320,  ..., -0.4566,  0.5969,  1.3384],
           │                         [ 1.5631,  0.2174,  0.6958,  ..., -1.4672,  0...
           └ RelDeformableTransformerDecoderLayer(
               (cross_attn): MSDeformAttn(
                 (sampling_offsets): Linear(in_features=256, out_featu...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-0.5163, -1.4466, -0.1320,  ..., -0.4566,  0.5969,  1.3384],
           │    │                      [-0.2687, -1.6835,  0.6709,  ..., -1.0583,  ...
           │    └ <function Module._call_impl at 0x000001A088341040>
           └ MultiheadAttention(
               (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
             )

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-0.5163, -1.4466, -0.1320,  ..., -0.4566,  0.5969,  1.3384],
           │                        [-0.2687, -1.6835,  0.6709,  ..., -1.0583,  ...
           └ <bound method MultiheadAttention.forward of MultiheadAttention(
               (out_proj): NonDynamicallyQuantizableLinear(in_features=512...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\activation.py", line 1275, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       │ └ <function multi_head_attention_forward at 0x000001A088505F70>
                                       └ <module 'torch.nn.functional' from 'C:\\Users\\ASUS\\.conda\\envs\\ilcn\\lib\\site-packages\\torch\\nn\\functional.py'>

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\functional.py", line 5400, in multi_head_attention_forward
    assert embed_dim == embed_dim_to_check, \
           │            └ 512
           └ 256

AssertionError: was expecting embedding dimension of 512, but got 256
2025-02-17 14:07:08.605 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-17 14:07:09.111 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-17 14:07:09.114 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-17 14:07:09.667 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-17 14:07:21.245 | ERROR    | __main__:<module>:328 - An error has been caught in function '<module>', process 'MainProcess' (17100), thread 'MainThread' (2764):
Traceback (most recent call last):

> File "main.py", line 328, in <module>
    main(args)
    │    └ Namespace(aux_loss=True, backbone='swin_tiny', batch_size=2, bbox_loss_coef=2.5, clip_max_norm=0.1, coco_panoptic_path=None, ...
    └ <function main at 0x00000253BB74E940>

  File "main.py", line 286, in main
    train_stats = train_one_epoch(
                  └ <function train_one_epoch at 0x00000253A2F6B040>

  File "D:\pro\ILCN\engine.py", line 45, in train_one_epoch
    outputs = model(samples)
              │     └ tensor([[[[-1.8953, -1.8953, -1.9124,  ...,  0.0000,  0.0000,  0.0000],
              │                 [-1.8953, -1.8953, -1.9124,  ...,  0.0000, ...
              └ PA2LG(
                  (transformer): DeformableTransformer(
                    (encoder): DeformableTransformerEncoder(
                      (layers): ModuleList(
                     ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-1.8953, -1.8953, -1.9124,  ...,  0.0000,  0.0000,  0.0000],
           │    │                       [-1.8953, -1.8953, -1.9124,  ...,  0.0000,...
           │    └ <function Module._call_impl at 0x000002539D2E3040>
           └ PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
                   (layers): ModuleList(
                  ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-1.8953, -1.8953, -1.9124,  ...,  0.0000,  0.0000,  0.0000],
           │                         [-1.8953, -1.8953, -1.9124,  ...,  0.0000,...
           └ <bound method PA2LG.forward of PA2LG(
               (transformer): DeformableTransformer(
                 (encoder): DeformableTransformerEncoder(
               ...

  File "D:\pro\ILCN\models\hoi.py", line 188, in forward
    h_hs, o_hs, rel_hs, layout, init_reference, inter_references = self.transformer(srcs, masks, pos, query_embeds)
                                                                   │                │     │      │    └ Parameter containing:
                                                                   │                │     │      │      tensor([[-0.1772, -1.0742, -0.3515,  ...,  0.8880, -1.0976, -0.2068],
                                                                   │                │     │      │              [-0.6940, -1.3653, -0.049...
                                                                   │                │     │      └ [tensor([[[[ 3.9260e-02,  3.9260e-02,  3.9260e-02,  ..., -9.6261e-02,
                                                                   │                │     │                   -9.6261e-02, -9.6261e-02],
                                                                   │                │     │                  [ 1.175...
                                                                   │                │     └ [tensor([[[False, False, False,  ...,  True,  True,  True],
                                                                   │                │                [False, False, False,  ...,  True,  True,  True],
                                                                   │                │             ...
                                                                   │                └ [tensor([[[[ 8.4783e-01, -2.7520e-01, -6.5010e-01,  ..., -7.4776e-01,
                                                                   │                             -4.4010e-01, -3.2981e-01],
                                                                   │                            [ 1.994...
                                                                   └ PA2LG(
                                                                       (transformer): DeformableTransformer(
                                                                         (encoder): DeformableTransformerEncoder(
                                                                           (layers): ModuleList(
                                                                          ...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ ([tensor([[[[ 8.4783e-01, -2.7520e-01, -6.5010e-01,  ..., -7.4776e-01,
           │    │                        -4.4010e-01, -3.2981e-01],
           │    │                       [ 1.99...
           │    └ <function Module._call_impl at 0x000002539D2E3040>
           └ DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers): ModuleList(
                   (0-5): 6 x DeformableTransf...

  File "C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ ([tensor([[[[ 8.4783e-01, -2.7520e-01, -6.5010e-01,  ..., -7.4776e-01,
           │                          -4.4010e-01, -3.2981e-01],
           │                         [ 1.99...
           └ <bound method DeformableTransformer.forward of DeformableTransformer(
               (encoder): DeformableTransformerEncoder(
                 (layers)...

  File "D:\pro\ILCN\models\deformable_transformer.py", line 139, in forward
    h_hs, o_hs, rel_hs, inter_references = self.decoder(tgt, reference_points, memory, spatial_shapes,
                                           │            │    │                 │       └ tensor([[ 80, 101],
                                           │            │    │                 │                 [ 40,  51],
                                           │            │    │                 │                 [ 20,  26],
                                           │            │    │                 │                 [ 10,  13]], device='cuda:0')
                                           │            │    │                 └ tensor([[[ 0.0278, -0.1152,  0.1710,  ..., -0.0782, -0.0270,  0.0654],
                                           │            │    │                            [-0.0212, -0.1207,  0.0783,  ..., -0.0552, -0...
                                           │            │    └ tensor([[[0.9091, 0.7599],
                                           │            │               [0.6310, 0.5011],
                                           │            │               [0.6757, 0.0971],
                                           │            │               [0.5827, 0.6982],
                                           │            │               [0.8217,...
                                           │            └ tensor([[[ 0.2327, -0.6274, -0.5258,  ...,  0.8880, -1.0976, -0.2068],
                                           │                       [ 0.2671,  0.6365, -1.2759,  ..., -0.1221,  0...
                                           └ DeformableTransformer(
                                               (encoder): DeformableTransformerEncoder(
                                                 (layers): ModuleList(
                                                   (0-5): 6 x DeformableTransf...

ValueError: too many values to unpack (expected 4)
2025-02-17 14:07:43.181 | INFO     | __main__:main:169 - Training log of QAHOI
2025-02-17 14:07:43.655 | INFO     | __main__:main:170 - 
----------------------  ------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
numpy                   1.24.1
cvpods._C               failed to import
cvpods_ENV_MODULE       <not set>
PyTorch                 2.4.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce GTX 1650
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
NVCC                    Not Available
Pillow                  10.2.0
torchvision             0.19.1+cu124 @C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision
torchvision arch flags  C:\Users\ASUS\.conda\envs\ilcn\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930154
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.1-Product Build 20240722 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

2025-02-17 14:07:43.657 | INFO     | __main__:main:171 - 
------------------------  ----------------------------------------------------
lr                        0.0001
lr_backbone_names         ['backbone.0']
lr_backbone               1e-05
lr_linear_proj_names      ['reference_points', 'sampling_offsets']
lr_linear_proj_mult       1.0
batch_size                2
weight_decay              0.0001
epochs                    100
lr_drop                   60
lr_drop_epochs
clip_max_norm             0.1
nms_thresh                0.5
use_checkpoint            False
no_obj                    False
frozen_weights
backbone                  swin_tiny
dilation                  False
position_embedding        sine
position_embedding_scale  6.283185307179586
num_feature_levels        4
enc_layers                6
dec_layers                6
dim_feedforward           1024
hidden_dim                256
dropout                   0.1
nheads                    8
num_queries               128
dec_n_points              4
enc_n_points              4
masks                     False
pretrained
num_verb_classes          117
num_obj_classes           80
subject_category_id       0
aux_loss                  True
set_cost_class            1
set_cost_bbox             2.5
set_cost_giou             1
set_cost_obj_class        1
set_cost_verb_class       1
mask_loss_coef            1
dice_loss_coef            1
bbox_loss_coef            2.5
giou_loss_coef            1
obj_loss_coef             1
verb_loss_coef            1
eos_coef                  0.1
dataset_file              hico
coco_path                 ./data/coco
coco_panoptic_path
remove_difficult          False
hoi_path                  ./data/hico_20160224_det
output_dir                hico_logs/all_flow
device                    cuda
seed                      42
resume                    ./params/swin_tiny_iterative_box_refinement_COCO.pth
start_epoch               0
eval                      False
eval_extra                False
use_nms                   True
num_workers               2
local_rank                -1
distributed               False
------------------------  ----------------------------------------------------
2025-02-17 14:07:44.213 | INFO     | __main__:main:191 - 
PA2LG(
  (transformer): DeformableTransformer(
    (encoder): DeformableTransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerEncoderLayer(
          (self_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout2): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): DeformableTransformerDecoder(
      (layers): ModuleList(
        (0-5): 6 x DeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (rel_layers): ModuleList(
        (0-5): 6 x RelDeformableTransformerDecoderLayer(
          (cross_attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
            (attention_weights): Linear(in_features=256, out_features=128, bias=True)
            (value_proj): Linear(in_features=256, out_features=256, bias=True)
            (output_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout1): Dropout(p=0.1, inplace=False)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (dropout2): Dropout(p=0.1, inplace=False)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear1): Linear(in_features=256, out_features=1024, bias=True)
          (dropout3): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=1024, out_features=256, bias=True)
          (dropout4): Dropout(p=0.1, inplace=False)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear3): Linear(in_features=36, out_features=256, bias=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear4): Linear(in_features=256, out_features=1024, bias=True)
          (dropout5): Dropout(p=0.1, inplace=False)
          (linear5): Linear(in_features=1024, out_features=256, bias=True)
          (dropout6): Dropout(p=0.1, inplace=False)
          (norm5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (linear_pro): Linear(in_features=256, out_features=128, bias=True)
          (linear_lay): Linear(in_features=256, out_features=128, bias=True)
        )
      )
      (sub_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (obj_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=80, bias=True)
  )
  (verb_class_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (sub_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (obj_embed): ModuleList(
    (0-5): 6 x MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (spatial_embed): ModuleList(
    (0-5): 6 x Linear(in_features=256, out_features=117, bias=True)
  )
  (query_embed): Embedding(128, 512)
  (input_proj): ModuleList(
    (0): Sequential(
      (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (1): Sequential(
      (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (2): Sequential(
      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (3): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
  )
  (backbone): Joiner(
    (0): Backbone(
      (body): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): PositionEmbeddingSine()
  )
)
2025-02-17 14:07:57.241 | INFO     | util.misc:log_every:287 - 
Epoch: [0]  [    0/18816]  eta: 2 days, 11:15:05  lr: 0.000100  obj_class_error: 100.00  loss: 105.0257 (105.0257)  loss_obj_ce: 1.0419 (1.0419)  loss_verb_ce: 9.0597 (9.0597)  loss_sub_bbox: 2.8908 (2.8908)  loss_obj_bbox: 2.7149 (2.7149)  loss_sub_giou: 1.0000 (1.0000)  loss_obj_giou: 1.0432 (1.0432)  loss_obj_ce_0: 0.9547 (0.9547)  loss_verb_ce_0: 9.1179 (9.1179)  loss_sub_bbox_0: 2.3231 (2.3231)  loss_obj_bbox_0: 2.0721 (2.0721)  loss_sub_giou_0: 0.9542 (0.9542)  loss_obj_giou_0: 0.9993 (0.9993)  loss_obj_ce_1: 1.0257 (1.0257)  loss_verb_ce_1: 9.3226 (9.3226)  loss_sub_bbox_1: 2.8292 (2.8292)  loss_obj_bbox_1: 2.5782 (2.5782)  loss_sub_giou_1: 0.9984 (0.9984)  loss_obj_giou_1: 1.0457 (1.0457)  loss_obj_ce_2: 0.9686 (0.9686)  loss_verb_ce_2: 9.3180 (9.3180)  loss_sub_bbox_2: 2.8751 (2.8751)  loss_obj_bbox_2: 2.7472 (2.7472)  loss_sub_giou_2: 1.0012 (1.0012)  loss_obj_giou_2: 1.0849 (1.0849)  loss_obj_ce_3: 0.9645 (0.9645)  loss_verb_ce_3: 8.9301 (8.9301)  loss_sub_bbox_3: 2.8858 (2.8858)  loss_obj_bbox_3: 2.7579 (2.7579)  loss_sub_giou_3: 1.0004 (1.0004)  loss_obj_giou_3: 1.0835 (1.0835)  loss_obj_ce_4: 0.9793 (0.9793)  loss_verb_ce_4: 8.7100 (8.7100)  loss_sub_bbox_4: 2.9164 (2.9164)  loss_obj_bbox_4: 2.7902 (2.7902)  loss_sub_giou_4: 1.0000 (1.0000)  loss_obj_giou_4: 1.0410 (1.0410)  loss_obj_ce_unscaled: 1.0419 (1.0419)  obj_class_error_unscaled: 100.0000 (100.0000)  loss_verb_ce_unscaled: 9.0597 (9.0597)  loss_sub_bbox_unscaled: 1.1563 (1.1563)  loss_obj_bbox_unscaled: 1.0860 (1.0860)  loss_sub_giou_unscaled: 1.0000 (1.0000)  loss_obj_giou_unscaled: 1.0432 (1.0432)  obj_cardinality_error_unscaled: 62.0000 (62.0000)  loss_obj_ce_0_unscaled: 0.9547 (0.9547)  loss_verb_ce_0_unscaled: 9.1179 (9.1179)  loss_sub_bbox_0_unscaled: 0.9292 (0.9292)  loss_obj_bbox_0_unscaled: 0.8288 (0.8288)  loss_sub_giou_0_unscaled: 0.9542 (0.9542)  loss_obj_giou_0_unscaled: 0.9993 (0.9993)  obj_cardinality_error_0_unscaled: 62.0000 (62.0000)  loss_obj_ce_1_unscaled: 1.0257 (1.0257)  loss_verb_ce_1_unscaled: 9.3226 (9.3226)  loss_sub_bbox_1_unscaled: 1.1317 (1.1317)  loss_obj_bbox_1_unscaled: 1.0313 (1.0313)  loss_sub_giou_1_unscaled: 0.9984 (0.9984)  loss_obj_giou_1_unscaled: 1.0457 (1.0457)  obj_cardinality_error_1_unscaled: 62.0000 (62.0000)  loss_obj_ce_2_unscaled: 0.9686 (0.9686)  loss_verb_ce_2_unscaled: 9.3180 (9.3180)  loss_sub_bbox_2_unscaled: 1.1501 (1.1501)  loss_obj_bbox_2_unscaled: 1.0989 (1.0989)  loss_sub_giou_2_unscaled: 1.0012 (1.0012)  loss_obj_giou_2_unscaled: 1.0849 (1.0849)  obj_cardinality_error_2_unscaled: 62.0000 (62.0000)  loss_obj_ce_3_unscaled: 0.9645 (0.9645)  loss_verb_ce_3_unscaled: 8.9301 (8.9301)  loss_sub_bbox_3_unscaled: 1.1543 (1.1543)  loss_obj_bbox_3_unscaled: 1.1032 (1.1032)  loss_sub_giou_3_unscaled: 1.0004 (1.0004)  loss_obj_giou_3_unscaled: 1.0835 (1.0835)  obj_cardinality_error_3_unscaled: 62.0000 (62.0000)  loss_obj_ce_4_unscaled: 0.9793 (0.9793)  loss_verb_ce_4_unscaled: 8.7100 (8.7100)  loss_sub_bbox_4_unscaled: 1.1666 (1.1666)  loss_obj_bbox_4_unscaled: 1.1161 (1.1161)  loss_sub_giou_4_unscaled: 1.0000 (1.0000)  loss_obj_giou_4_unscaled: 1.0410 (1.0410)  obj_cardinality_error_4_unscaled: 62.0000 (62.0000)  time: 11.3364  data: 6.3845  max mem: 5224
